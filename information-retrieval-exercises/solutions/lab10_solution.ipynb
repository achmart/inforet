{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVXOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Machine Learning tasks are typically thought of optimization problems, e.g. minimizing an error function or maximizing a probability. Ideally, the optimization problem turns out to be convex, which implies that any local minimum is the global minimum of the formulation, and what is even more important, we can.  In the following, it will be assumed that you have some basic knowledge about convex optimization. The intention of this task is to familiarize ourselves with CVXOPT, one of the most-widely used convex optimization toolboxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)  Go to `cvxopt.org` and follow the installation instructions for your distribution. For conda, you need to run\n",
    "`conda install -c conda-forge cvxopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Skim through the **Examples** section on `cvxopt.org` to get an overview of the functionality of the different solvers of CVXOPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implement a function `minsq` which expects a NumPy array `A` of shape `(m,n)` and a NumPy array `y` of shape `(m,)` as its arguments and returns a NumPy array `x` of shape `(n,)` that solves the following problem.\n",
    "\n",
    "<center>$\\mathrm{min_\\mathbf{x}} \\|\\mathbf A\\mathbf{x}-\\mathbf{y}\\|$.</center>\n",
    "\n",
    "Test your function by feeding it with appropriate inputs and comparing the results with the ones you get by using `np.linalg.pinv`. Experiment by adding white Gaussian noise to `y`. If CVXOPT does not accept your NumPy arrays, try casting them to `double`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[ 10  40]\n",
      " [ 20   0]\n",
      " [-30  40]]\n",
      "y: [ 50.26820525  19.85289625  10.83075534]\n",
      "x: [ 0.98817244  1.01078012]\n",
      "np.dot(pinv(A),y): [ 0.98817244  1.01078012]\n"
     ]
    }
   ],
   "source": [
    "def minsq(A, y):\n",
    "    P=matrix(np.dot(A.T,A).astype('double'))\n",
    "    q=matrix(-np.dot(A.T,y).astype('double'))\n",
    "    x=solvers.qp(P,q)\n",
    "    return np.array(x['x'])\n",
    "\n",
    "A=np.array([[10, 40],[20, 0],[-30, 40]])\n",
    "y=np.array([50,20,10])+np.random.randn(3,)\n",
    "\n",
    "print('A:', A)\n",
    "print('y:', y)\n",
    "print('x:', minsq(A,y).squeeze())\n",
    "print('np.dot(pinv(A),y):', np.dot(np.linalg.pinv(A),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Consider the equation (8.30) in the lecture notes. Implement a function `solvedualsvm(H,y)` that returns the solution `lambda_star` of the dual SVM problem by means of CVXOPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvedualsvm(H,y):\n",
    "    y=y.squeeze()\n",
    "    n=len(y)\n",
    "    G=-np.eye(n).astype('double')\n",
    "    A=y.reshape(1,n).astype('double')\n",
    "    h=np.zeros((n,)).astype('double')\n",
    "    b=np.zeros((1,)).astype('double')\n",
    "    P=H.astype('double')\n",
    "    q=-np.ones((n,)).astype('double')\n",
    "    lambda_star=solvers.qp(matrix(P),matrix(q),matrix(G),matrix(h),matrix(A),matrix(b))\n",
    "    return lambda_star['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function with the training data\n",
    "\t\t\\begin{equation*}\n",
    "\t\t\\begin{split}\n",
    "\t\t\\mathbf{x}_1=\\begin{bmatrix}-1\\\\-1\\end{bmatrix},y_1=-1,&\\ \\mathbf{x}_2=\\begin{bmatrix}-2\\\\-2\\end{bmatrix},y_2=-1,\\\\\n",
    "\t\t\\mathbf{x}_3=\\begin{bmatrix}1\\\\1\\end{bmatrix},y_3=1,&\\ \\mathbf{x}_4=\\begin{bmatrix}2\\\\2\\end{bmatrix},y_4=1,\\\n",
    "\t\t\\end{split}.\n",
    "\t\t\\end{equation*}\n",
    "\t\tVerify that the KKT conditions with respect to the support vectors are in line with what you expect. In the next lab course, we will use this function to implement linear and kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8980e-01 -8.9796e-01  6e+00  2e+00  1e+00\n",
      " 1: -1.8751e-01 -5.7797e-01  4e-01  2e-02  1e-02\n",
      " 2: -2.4373e-01 -2.8494e-01  4e-02  1e-16  2e-16\n",
      " 3: -2.4987e-01 -2.5034e-01  5e-04  8e-17  4e-16\n",
      " 4: -2.5000e-01 -2.5000e-01  5e-06  6e-17  3e-16\n",
      " 5: -2.5000e-01 -2.5000e-01  5e-08  3e-17  4e-16\n",
      "Optimal solution found.\n",
      "[ 2.50e-01]\n",
      "[ 6.52e-09]\n",
      "[ 2.50e-01]\n",
      "[ 6.52e-09]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=np.array([[-1,-2,1,2],[-1,-2,1,2]])\n",
    "y=np.array([-1,-1,1,1])\n",
    "H=np.dot(np.dot(np.dot(np.diag(y),X.T),X),np.diag(y))\n",
    "lambda_star=solvedualsvm(H,y)\n",
    "print(lambda_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Only the KKT coefficients that belong to the support vectors are significantly larger than 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval in High Dimensional Data\n",
    "## Lab #2, 26.10.2017\n",
    "## Statistical Decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two dimensional, discrete random variable $X = [X_1\\,X_2]^T$ subjected to the joint probability density $p_X$ as described in the following table.\n",
    "\n",
    "$\\begin{array}{c||cc} p_X(X_1,X_2) & X_2=0 & X_2=1\\\\ \\hline\n",
    "X_1 = 0 & 0.4 & 0.3 \\\\\n",
    "X_1 = 1 & 0.2 & 0.1\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the marginal probability densities $p_{X_1}, p_{X_2}$ and the coonditional probability $P(X_2=0|X_1=0)$ as well as the expected value $\\mathbb{E}[X]$ and the covariance matrix $\\mathbb{E}[(X-\\mathbb{E}[X])(X-\\mathbb{E}[X])^T]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init needed variables\n",
    "joint_prob = np.array([[0.4, 0.3], [0.2, 0.1]])\n",
    "results = np.array([[0, 1, 0, 1],\n",
    "                    [0, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal distribution density px1: [ 0.7  0.3]\n",
      "Marginal distribution density px2:  [ 0.6  0.4]\n"
     ]
    }
   ],
   "source": [
    "px1 = np.sum(joint_prob, axis=1)\n",
    "px2 = np.sum(joint_prob, axis=0)\n",
    "\n",
    "print (\"Marginal distribution density px1: {}\".format(px1))\n",
    "print (\"Marginal distribution density px2: \",px2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probability P(X2=0|X1=0): 0.571\n"
     ]
    }
   ],
   "source": [
    "cond_prob = joint_prob[0][0]/px1[0]\n",
    "print (\"Conditional probability P(X2=0|X1=0): {:.3f}\".format(cond_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value EX: [ 0.3  0.4]\n"
     ]
    }
   ],
   "source": [
    "EX = np.dot(results, np.ravel(joint_prob, 'F'))\n",
    "print (\"Expected Value EX:\", EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix: \n",
      "[[ 0.21 -0.02]\n",
      " [-0.02  0.24]]\n"
     ]
    }
   ],
   "source": [
    "results_centered = results - np.reshape(EX, (2,1))\n",
    "CovX = np.dot(np.dot(results_centered, np.diag(joint_prob.ravel('F'))), results_centered.T)\n",
    "print (\"Covariance Matrix: \\n{}\".format(CovX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) Write a PYTHON function toyrnd that expects the positive integer parameter n as its input an returns a matrix $X$ of size (2,n), containing $n$ samples drawn independently from the distribution $p_X$, as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0\n",
      "  0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0\n",
      "  0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0\n",
      "  0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "  1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def toyrnd(n):\n",
    "    x1 = np.random.choice([0, 1], (1, n), p=px1)\n",
    "    x2 = np.random.choice([0, 1], (1, n), p=px2)\n",
    "    return np.vstack((x1,x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Verify your results in a) by generating 10000 samples with toyrnd and computing the respective empirical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Marginal distribution density p_x1: [ 0.6986  0.3014]\n",
      "Empirical Marginal distribution density p_x2:  [ 0.5997  0.4003]\n"
     ]
    }
   ],
   "source": [
    "samples = toyrnd(10000)\n",
    "\n",
    "p_x1equ1 = (samples[0].sum()/len(samples[0]))\n",
    "p_x2equ1 = (samples[1].sum()/len(samples[1]))\n",
    "p_x1 = np.array([1-p_x1equ1, p_x1equ1])\n",
    "p_x2 = np.array([1-p_x2equ1, p_x2equ1])\n",
    "\n",
    "print (\"Empirical Marginal distribution density p_x1: {}\".format(p_x1))\n",
    "print (\"Empirical Marginal distribution density p_x2: \",p_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986258230747209"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob_empirical = samples[1, samples[0,:]==0]\n",
    "np.sum(cond_prob_empirical==0)/len(cond_prob_empirical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2\n",
    "The MNS trainign set consists of handwritten digits from 0 to 9, stored as PNG files of size 28 x 28 an indexed by label. Download the provided ZIP file from Moodle and make yourself familiar with the directory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Grayscale images are typically described as matrices of uint8 values. For numerical calculations, it is more sensible to work with floating point numbers. Load two (arbitrary) images from the database and convert them to matrices I1 and I2 of float64 values in the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './mnist/d4/'\n",
    "filenames = os.listdir(path)\n",
    "im1 = imageio.imread(path + filenames[0])\n",
    "I1 = im1/255\n",
    "im2 = imageio.imread(path +  filenames[10])\n",
    "I2 = im2/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The matrix equivalent of te euclidean norm $\\| \\cdot \\|_2$ is the $Frobenius$ norm. For any matrix $\\mathbf{A} \\in \\mathbb{R}^{m\\, \\times \\, n}$, it is defined as\n",
    "\n",
    "\\begin{equation} \\|\\mathbf{A}\\|_F = \\sqrt{tr(\\mathbf{A}^T\\mathbf{A})} \\end{equation}\n",
    "\n",
    "where tr denotes the trace of a matrix. Compute the distance $\\|\\mathbf{I}_1 - \\mathbf{I}_2 \\|_F$ between the images I1 and I2 using three different procedures in PYTHON:\n",
    "- Running the numpy.linalg.norm function with the 'fro' parameter\n",
    "- Directly applying formula (1)\n",
    "- Computing the euclidean norm between the vectorized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = I1 - I2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0642043267400751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1 = np.linalg.norm(D, ord='fro')\n",
    "dist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0642043267400751"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2 = np.sqrt(np.trace(np.dot(D.T,D)))\n",
    "dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0642043267400751"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.reshape(D, 784)\n",
    "dist3 = np.linalg.norm(d)\n",
    "dist3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) In the following, we want to solve a simple classification problem by applying <i>k-Nearest Neighbors</i>. To this end, choose two digits classes, e.g. 0 and 1, and lod n_train = 500 images from each class to the workspace. Convert them according to subtask a) and store them in vectorized form in the matrix X_train of size (784, 2*n_train). Provide an indicator vector Y_train pf length 2*n_train that assigns the respective digit class label to each column of X_train.  \n",
    "From each of the two classes, choose another set of n_test=10 images and create according matrices X_test and Y_test. Now, for each sample in the test set, determine the k = 20 training samples with the smallest Frobenius distance to it and store their indices in the (2*n_test, k) matrix NN. Generate a vector Y_kNN containing the respective estimated class labels by performing a majority vote on NN. Compare the result with Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((784, 1000))\n",
    "Y_train = np.zeros(1000, dtype='int64')\n",
    "digitclass0 = 0\n",
    "digitclass1 = 1\n",
    "path0 = './mnist/d' + str(digitclass0) +'/'\n",
    "path1 = './mnist/d' + str(digitclass1) +'/'\n",
    "filenames0 = os.listdir(path0)\n",
    "filenames1 = os.listdir(path1)\n",
    "\n",
    "for i in range(500):\n",
    "    im0 = imageio.imread(path0 + filenames0[i])\n",
    "    im1 = imageio.imread(path1 + filenames1[i])\n",
    "    X_train[:, i] = np.reshape(im0, 784)/255\n",
    "    X_train[:, 500 + i] = np.reshape(im1, 784)/255\n",
    "    Y_train[i] = digitclass0\n",
    "    Y_train[500 + i] = digitclass1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros((784, 20))\n",
    "Y_test = np.zeros(20, dtype='int64')\n",
    "\n",
    "for i in range(500, 510):\n",
    "    im0 = imageio.imread(path0 + filenames0[i])\n",
    "    im1 = imageio.imread(path1 + filenames1[i])\n",
    "    X_test[:, i-500] = np.reshape(im0, 784)\n",
    "    X_test[:, i-490] = np.reshape(im1, 784)\n",
    "    Y_test[i - 500] = digitclass0\n",
    "    Y_test[i - 490]= digitclass1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros(1000)\n",
    "NN = np.zeros((20, 20))\n",
    "Y_kNN = np.zeros(20, dtype='int64')\n",
    "for i in range(20):\n",
    "    for j in range(1000):\n",
    "        DIFF = X_test[:, i] - X_train[:, j]\n",
    "        distances[j] = np.linalg.norm(DIFF)\n",
    "    indices = np.argsort(distances)\n",
    "    labels = Y_train[indices[:20]]\n",
    "    bins = np.bincount(labels)\n",
    "    Y_kNN[i] = np.argsort(bins)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels determined by k-Nearest Neighbors:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Labels of training set\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Labels determined by k-Nearest Neighbors:')\n",
    "print(Y_kNN)\n",
    "print('\\nLabels of training set')\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
